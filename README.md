# awesome-robotic-foundation-models
A vast array of Multi-Modal Embodied Robotic Foundation Models!

# Models


| Model Name              | Capabilities                                                                                                    | Multi-Modal | Model Type     | License         | Last Updated  |
|-------------------------|-----------------------------------------------------------------------------------------------------------------|-------------|----------------|-----------------|---------------|
| RT-X                    | Computer Vision, AI, Vision, Attention Model, Multimodal, Vision Transformer                                   | Yes         | Pytorch        | MIT License     | 3 days ago    |
| VIMA                    | General Robot Manipulation with Multimodal Prompts                                                              | Yes         | Python         | MIT License     | Last week     |
| SayCan                  | Grounding Language in Robotic Affordances                                                                       | No          | Python         | MIT License     | Last week     |
| AutoRT                  | Large Scale Orchestration of Robotic Agents                                                                     | No          | Python         | MIT License     | Last week     |
| Awesome-LLM-Robotics    | Comprehensive list for Robotics/RL using LLM/multi-modal models                                                 | Yes         | -              | BSD 3-Clause    | Oct 11, 2023  |
| RoboCAT                 | Self-Improving Foundation Agent for Robotic Manipulation                                                        | No          | Python         | MIT License     | Sep 4, 2023   |
| NeoCortex               | Foundation Model for Humanoid robots                                                                            | Yes         | Python         | MIT License     | Aug 25, 2023  |
| CyberTron               | Suite of embodied multi-modal robotic transformers                                                              | Yes         | Python         | MIT License     | Aug 16, 2023  |
| PALM-E                  | Embodied Multimodal Language Model, Diverse Joint Training across Language, Vision, Visual-Language Domains    | Yes         | Open Source    | -               | -             |
| HRTX                    | Multi-Modal Multi-Embodied Hivemind-like Iteration of RTX-2                                                     | Yes         | -              | -               | -             |
| RT1                     | Part of RT-X, Embodied Robotic Learning Datasets and Models                                                     | Yes         | Pytorch        | MIT License     | 3 days ago    |
| RT2                     | New model translates vision and language into action                                                            | No          | -              | -               | -             |




## ðŸ«¶ Contributions:

The easiest way to contribute is to pick any issue with the `good first issue` tag ðŸ’ª. Read the Contributing guidelines [here](/CONTRIBUTING.md). Bug Report? [File here](https://github.com/swarms/gateway/issues) | Feature Request? [File here](https://github.com/swarms/gateway/issues)

Swarms is an open-source project, and contributions are VERY welcome. If you want to contribute, you can create new features, fix bugs, or improve the infrastructure. Please refer to the [CONTRIBUTING.md](https://github.com/kyegomez/swarms/blob/master/CONTRIBUTING.md) and our [contributing board](https://github.com/users/kyegomez/projects/1) to participate in Roadmap discussions!

<a href="https://github.com/kyegomez/swarms/graphs/contributors">
  <img src="https://contrib.rocks/image?repo=kyegomez/swarms" />
</a>

----

## Community

Join our growing community around the world, for real-time support, ideas, and discussions on Swarms ðŸ˜Š 

- View our official [Blog](https://swarms.apac.ai)
- Chat live with us on [Discord](https://discord.gg/kS3rwKs3ZC)
- Follow us on [Twitter](https://twitter.com/kyegomez)
- Connect with us on [LinkedIn](https://www.linkedin.com/company/the-swarm-corporation)
- Visit us on [YouTube](https://www.youtube.com/channel/UC9yXyitkbU_WSy7bd_41SqQ)
- [Join the Swarms community on Discord!](https://discord.gg/AJazBmhKnr)
- Join our Swarms Community Gathering every Thursday at 1pm NYC Time to unlock the potential of autonomous agents in automating your daily tasks [Sign up here](https://lu.ma/5p2jnc2v)

---

## Discovery Call
Book a discovery call to learn how Swarms can lower your operating costs by 40% with swarms of autonomous agents in lightspeed. [Click here to book a time that works for you!](https://calendly.com/swarm-corp)


## Accelerate Backlog
Help us accelerate our backlog by supporting us financially! Note, we're an open source corporation and so all the revenue we generate is through donations at the moment ;)

<a href="https://polar.sh/kyegomez"><img src="https://polar.sh/embed/fund-our-backlog.svg?org=kyegomez" /></a>

